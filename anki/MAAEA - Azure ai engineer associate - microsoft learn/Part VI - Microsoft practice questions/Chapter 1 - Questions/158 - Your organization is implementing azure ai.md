========== Question ==========  

### Your organization is implementing Azure AI Foundry Content Safety to moderate user-generated content on a social messaging platform.

You need to configure Foundry Content Safety to identify and restrict harmful text content, including profanities and hate speech, while allowing customization for specific patterns.

Each correct answer presents part of the solution. Which two actions should you take?

Select all answers that apply.

-   Configure harmful patterns using the Custom Categories API.

-   Enable built-in blocklists in Content Safety Studio.

-   Enable encryption at rest with customer-managed keys.

-   Use the Analyze Image API for text analysis.  

========== Answer ==========  

---

###### 1. Configure harmful patterns using the Custom Categories API.

###### 2. Enable built-in blocklists in Content Safety Studio.

Enabling built-in blocklists in Content Safety Studio is essential as it provides predefined terms to effectively flag harmful content such as profanities and hate speech. Configuring harmful patterns using the Custom Categories API allows for tailored moderation by defining specific patterns that align with organizational needs. Enabling encryption at rest with customer-managed keys enhances data security but does not contribute to the detection or restriction of harmful text content. Using the Analyze Image API focuses on image moderation and is not applicable to the task of moderating text content.

[Azure AI services - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/3-azure-ai-services)

[Use the Azure Document Intelligence Studio - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/work-form-recognizer/9-form-recognizer-studio)

========== Id ==========  
158

---

DECK INFO

TARGET DECK: Programming::Cloud::Azure::MAAEA - Azure ai engineer associate - microsoft learn::Part VI - Microsoft practice questions::Chapter 1 - Questions

FILE TAGS: #Programming::#Cloud::#Azure::#AI-102::#MAAEA-Azure-ai-engineer-associate-microsoft-learn::#Part-VI-Microsoft-practice-questions::#Chapter-1-Questions::#158-Your-organization-is-implementing-azure-ai

Tags:

Reference:

Related:

```dataview
LIST
where file.name = this.file.name
```

QUESTION STATUS: Safe to store
