========== Question ==========  

### You are building a custom copilot based on Azure OpenAI.

You discover attempts to exploit the copilot by jailbreaking it through a User Prompt Injection Attack (UPIA).

You need to increase security to prevent the jailbreak attack.

Which Azure AI Foundry Service should you include in the solution?

Select only one answer.

-   Content Safety

-   Face

-   Language

-   Video Indexer

-   Vision  

========== Answer ==========  

---

###### 1. Content Safety

Content Safety jailbreak risk detection recognizes four different classes of jailbreak attacks: Attempt to change system rules, embedding a conversation mockup to confuse the modelâ€¯, role-play, and encoding attacks. These can be used in LLM-based applications to prevent jailbreak attacks. All the other services listed are designed for different purposes.

[Jailbreak risk detection in Azure AI Content Safety - Azure AI services | Microsoft Learn](https://learn.microsoft.com/azure/ai-services/content-safety/concepts/jailbreak-detection)

[What are Azure AI services? - Azure AI services | Microsoft Learn](https://learn.microsoft.com/azure/ai-services/what-are-ai-services)

========== Id ==========  
156

---

DECK INFO

TARGET DECK: Programming::Cloud::Azure::MAAEA - Azure ai engineer associate - microsoft learn::Part VI - Microsoft practice questions::Chapter 1 - Questions

FILE TAGS: #Programming::#Cloud::#Azure::#AI-102::#MAAEA-Azure-ai-engineer-associate-microsoft-learn::#Part-VI-Microsoft-practice-questions::#Chapter-1-Questions::#156-You-are-building-a-custom-copilot-based-on

Tags:

Reference:

Related:

```dataview
LIST
where file.name = this.file.name
```

QUESTION STATUS: Safe to store
